{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63OvI0zGNhey"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7oRS1MmNj60"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = '/content/gdrive/MyDrive/DeXpression'\n",
        "os.chdir(path)\n",
        "\n",
        "DATA_FOLDER = '/content/gdrive/MyDrive/DeXpression/data/'\n",
        "RESULTS_FOLDER = '/content/gdrive/MyDrive/DeXpression/results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu3MccCA9dX5"
      },
      "source": [
        "Standard imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ga62fJx82jX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU, LogSoftmax\n",
        "\n",
        "from torch.nn import LayerNorm, BatchNorm2d, Dropout\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bklaM2Vy9g_2"
      },
      "source": [
        "#DeXpression model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaeCVAjGJa-X"
      },
      "source": [
        "Transfer to GPU (if applicable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JG-A9mBJahp"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuSnqlwBQpmk"
      },
      "outputs": [],
      "source": [
        "class DeXpression(Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(DeXpression, self).__init__()\n",
        "\n",
        "    # block-1\n",
        "    self.conv1 = Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "    self.pool1 = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "    self.lrn1  = LayerNorm([64, 55, 55])\n",
        "\n",
        "    # feature extractor 1\n",
        "    self.conv2a = Conv2d(in_channels=64, out_channels=96, kernel_size=1, stride=1, padding=0)\n",
        "    self.conv2b = Conv2d(in_channels=96, out_channels=208, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool2a = MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2c = Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "    self.pool2b = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    # feature extractor 2\n",
        "    self.conv3a = Conv2d(in_channels=272, out_channels=96, kernel_size=1, stride=1, padding=0)\n",
        "    self.conv3b = Conv2d(in_channels=96, out_channels=208, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool3a = MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3c = Conv2d(in_channels=272, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "    self.pool3b = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    # fully connected layer \n",
        "    self.fc                  = Linear(in_features=272*13*13, out_features=7)\n",
        "    self.softmax             = LogSoftmax(dim=1)\n",
        "    self.batch_normalization = BatchNorm2d(272)\n",
        "    self.dropout             = Dropout(p=0.2)\n",
        "\n",
        "  def forward(self, x, dropout=True, batch_normalization=True):\n",
        "    \"\"\"\n",
        "    Perform a single step of forward propogation\n",
        "    \"\"\"\n",
        "    # block-1\n",
        "    conv1_out = F.relu(self.conv1(x))\n",
        "    pool1_out = self.pool1(conv1_out)\n",
        "    lrn1_out  = self.lrn1(pool1_out)\n",
        "\n",
        "    # feature extractor 1\n",
        "    # branch 1\n",
        "    conv2a_out = F.relu(self.conv2a(lrn1_out))\n",
        "    conv2b_out = F.relu(self.conv2b(conv2a_out))\n",
        "    # branch 2\n",
        "    pool2a_out = self.pool2a(lrn1_out)\n",
        "    conv2c_out = F.relu(self.conv2c(pool2a_out))\n",
        "    # concatenate both branches\n",
        "    concat2_out = torch.cat((conv2b_out, conv2c_out), 1)\n",
        "    pool2b_out  = self.pool2b(concat2_out)\n",
        "\n",
        "    # feature extractor 2\n",
        "    # branch 1\n",
        "    conv3a_out = F.relu(self.conv3a(pool2b_out))\n",
        "    conv3b_out = F.relu(self.conv3b(conv3a_out))\n",
        "    # branch 2\n",
        "    pool3a_out = self.pool3a(pool2b_out)\n",
        "    conv3c_out = F.relu(self.conv3c(pool3a_out))\n",
        "    # concatenate both branches\n",
        "    concat3_out = torch.cat((conv3b_out, conv3c_out), 1)\n",
        "    pool3b_out  = self.pool3b(concat3_out)\n",
        "\n",
        "    # dropout enabled\n",
        "    if dropout:\n",
        "      pool3b_out = self.dropout(pool3b_out)\n",
        "    \n",
        "    # batch normalization enabled\n",
        "    if batch_normalization:\n",
        "      pool3b_out = self.batch_normalization(pool3b_out)\n",
        "\n",
        "    pool3b_shape = pool3b_out.shape\n",
        "    pool3b_flat  = pool3b_out.reshape([-1, pool3b_shape[1] * pool3b_shape[2] * pool3b_shape[3]])\n",
        "\n",
        "    output = self.fc(pool3b_flat)\n",
        "    logits = self.softmax(output)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ljF9f9Pflw"
      },
      "source": [
        "Utility functions to read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUcyA7ECPi7H"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "from matplotlib import image as im\n",
        "\n",
        "def data(*paths):\n",
        "  return os.path.join(DATA_FOLDER, *paths)\n",
        "\n",
        "def results(*paths):\n",
        "  return os.path.join(RESULTS_FOLDER, *paths)\n",
        "\n",
        "\n",
        "def read_file(img_file, label_file):\n",
        "  \"\"\"\n",
        "  Read and convert images to numpy arrays\n",
        "  \"\"\"\n",
        "  image = im.imread(img_file)\n",
        "\n",
        "  with open(label_file, \"r\") as file:\n",
        "        label = float(file.read())\n",
        "\n",
        "  return image, label\n",
        "\n",
        "\n",
        "def load_from_array():\n",
        "  \"\"\"\n",
        "  Load dataset from a specified folder\n",
        "  \"\"\"\n",
        "  x = np.load(data(\"x.npy\")).reshape(-1, 1, 224, 224)\n",
        "  y = np.load(data(\"y.npy\"))\n",
        "\n",
        "  return x, y\n",
        "\n",
        "\n",
        "def save_to_array():\n",
        "  \"\"\"\n",
        "  Save dataset to a specified folder\n",
        "  \"\"\"\n",
        "  with open(data(\"x.npy\"), \"wb\") as file:\n",
        "    np.save(file, x)\n",
        "\n",
        "  with open(data(\"y.npy\"), \"wb\") as file:\n",
        "    np.save(file, y)\n",
        "\n",
        "\n",
        "def load_dataset(use_existing = True):\n",
        "  \"\"\"\n",
        "  Return input and output variables from the\n",
        "  dataset\n",
        "  \"\"\"\n",
        "  if use_existing:\n",
        "    x, y = load_from_array()\n",
        "  \n",
        "  else:\n",
        "    data_dir = DATA_FOLDER\n",
        "    images   = []\n",
        "    labels   = []\n",
        "\n",
        "    for image_file in sorted(glob.glob(f\"{data_dir}/**/*.png\")):\n",
        "      image_path = os.path.dirname(image_file)\n",
        "      label_path = image_path.replace(\"images\", \"labels\")\n",
        "\n",
        "      if os.path.exists(label_path):\n",
        "        if not len(os.listdir(label_path)) == 0:\n",
        "          label_file = os.path.join(label_path, os.listdir(label_path)[0])\n",
        "\n",
        "          image, label = file_reader(image_file, label_file)\n",
        "          images.append(image)\n",
        "          labels.append(label)\n",
        "\n",
        "    x = np.stack(images, axis = 0).reshape(-1, 1, 224, 224)\n",
        "    y = np.stack(labels, axis = 0)\n",
        "\n",
        "    save_to_array(x, y)\n",
        "\n",
        "\n",
        "  print(\"Loaded datasets {} and {}\".format(x.shape, y.shape))\n",
        "  print(\"\")\n",
        "\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NjnmZZuU_Vu"
      },
      "source": [
        "Dataset utilities (Shuffle and convert to torch tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQRb5L9oVD08"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle as s\n",
        "\n",
        "\n",
        "def kfold(x, y, splits = 10, shuffle = True):\n",
        "  \"\"\"\n",
        "  Perform a K-fold split on the dataset\n",
        "  x -> Input variables from the dataset\n",
        "  y -> Output variables frm the dataset\n",
        "  \"\"\"\n",
        "  x, y = s(x, y)\n",
        "  kfold = KFold(n_splits = splits, shuffle = shuffle)\n",
        "\n",
        "  for train, test in kfold.split(x, y):\n",
        "    x_train, y_train = x[train], y[train]\n",
        "    x_test, y_test   = x[test], y[test]\n",
        "\n",
        "    yield x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def convert_to_torch(x_train, y_train, x_test, y_test):\n",
        "  \"\"\"\n",
        "  Convert the train and test data to torch tensors\n",
        "  \"\"\"\n",
        "  # convert training images to a torch tensor\n",
        "  x_train = torch.from_numpy(x_train)\n",
        "  x_train = x_train.type(torch.FloatTensor)\n",
        "\n",
        "  # convert training labels to a torch tensor\n",
        "  y_train = y_train.astype(int)\n",
        "  y_train = torch.from_numpy(y_train)\n",
        "\n",
        "  # convert test images to torch tensor\n",
        "  x_test = torch.from_numpy(x_test)\n",
        "  x_test = x_test.type(torch.FloatTensor)\n",
        "\n",
        "  # convert testing labels to torch tensor\n",
        "  y_test = y_test.astype(int)\n",
        "  y_test = torch.from_numpy(y_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSopP8YUR3U5"
      },
      "source": [
        "Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn_ZXB91R4fE"
      },
      "outputs": [],
      "source": [
        "def initialize():\n",
        "  \"\"\"\n",
        "  Load model parameters to cuda\n",
        "  \"\"\"\n",
        "  model = DeXpression()\n",
        "  model = model.to(device)\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3LsCRg96HPd"
      },
      "source": [
        "Dump checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7u2Madx6Ppv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def dump_dict_list(history):\n",
        "  \"\"\"\n",
        "  Convert history to a pandas dataframe\n",
        "  and store it in the results folder\n",
        "  \"\"\"\n",
        "  filename = results(\"history.csv\")\n",
        "\n",
        "  print(\"Saving history {}\".format(filename))\n",
        "  print(\"\")\n",
        "\n",
        "  df = pd.DataFrame(history)\n",
        "  df.to_csv(filename)\n",
        "\n",
        "\n",
        "def print_progress(fold, epoch, n_epochs, avg_train_accuracy, avg_train_loss, avg_test_accuracy, avg_test_loss):\n",
        "  \"\"\"\n",
        "  Print training and testing performance\n",
        "  per epoch\n",
        "  \"\"\"\n",
        "  print(\"Fold: %d, Epoch: %d/%d\" %(fold+1, epoch+1, n_epochs))\n",
        "  print(\"Train accuracy: %.2f%%\" %(avg_train_accuracy * 100))\n",
        "  print(\"Train loss: %.3f\" %(avg_train_loss))\n",
        "  print(\"Test accuracy: %.2f%%\" %(avg_test_accuracy * 100))\n",
        "  print(\"Test loss: %.3f\" %(avg_test_loss))\n",
        "  print(\"\")\n",
        "\n",
        "\n",
        "def save_progress(fold, epoch, avg_test_accuracy, model, model_optimizer):\n",
        "  \"\"\"\n",
        "  Save a model checkpoint every epoch\n",
        "  \"\"\"\n",
        "  checkpoint = \"{:d}-{:.2f}.tar\".format(epoch + 1, avg_test_accuracy)\n",
        "\n",
        "  print(\"Saving checkpoint {}\".format(results(checkpoint)))\n",
        "  print(\"\")\n",
        "\n",
        "  # save in a dictionary\n",
        "  torch.save({\"fold\": fold + 1, \"epoch\": epoch + 1, \"model\": model.state_dict(), \"model_opt\": model_optimizer.state_dict()}, results(checkpoint))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul7gbdPk-DGG"
      },
      "source": [
        "#Utility functions for training, testing and running the model\n",
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPdaNNRD-Qow"
      },
      "outputs": [],
      "source": [
        "def train(x_batch, y_batch, model, criterion, model_optimizer):\n",
        "  \"\"\"\n",
        "  Perform a single forward and back propagation step\n",
        "  on the training data\n",
        "  \"\"\"\n",
        "\n",
        "  model_optimizer.zero_grad() # remove any existing gradients\n",
        "\n",
        "  # forward propagate\n",
        "  output     = model(x_batch)\n",
        "  _, y_pred  = torch.max(output.data, 1)\n",
        "  _, y_truth = torch.max(y_batch, 1)\n",
        "\n",
        "  # compute model loss\n",
        "  loss = criterion(output, y_truth)\n",
        "\n",
        "  # backpropagate the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # update parameters based on backprop\n",
        "  model_optimizer.step()\n",
        "\n",
        "  # accuracy\n",
        "  correct_counts = y_pred.eq(y_truth.data.view_as(y_pred))\n",
        "\n",
        "  # average accuracy\n",
        "  accuracy = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "  return accuracy, loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvWEK0lT_zTx"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h19peek_yhk"
      },
      "outputs": [],
      "source": [
        "def test(x_batch, y_batch, model, criterion):\n",
        "  \"\"\"\n",
        "  Perform a single forward propagation step\n",
        "  on the testing data\n",
        "  \"\"\"\n",
        "  # forward propagate\n",
        "  output     = model(x_batch)\n",
        "  _, y_pred  = torch.max(output.data, 1)\n",
        "  _, y_truth = torch.max(y_batch, 1)\n",
        "\n",
        "  # compute model loss\n",
        "  loss = criterion(output, y_truth)\n",
        "\n",
        "  # compute validation accuracy\n",
        "  correct_counts = y_pred.eq(y_truth.data.view_as(y_pred))\n",
        "\n",
        "  # mean validation accuracy\n",
        "  accuracy = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "  # predicted and ground truth values converted to a list\n",
        "  y_pred  = y_pred.tolist()\n",
        "  y_truth = y_truth.tolist()\n",
        "\n",
        "  return accuracy, loss, y_pred, y_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umD_muStBUk3"
      },
      "source": [
        "Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDxpwSzQBXF_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "history = []\n",
        "\n",
        "\n",
        "def run_model(fold, model, x_train, y_train, x_test, y_test, batch_size=32, n_epochs=2, learning_rate=0.001):\n",
        "\n",
        "  global history # for model checkpoints\n",
        "\n",
        "  # loss function and optimizer\n",
        "  criterion       = nn.NLLLoss()\n",
        "  model_optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    running_train_accuracy = 0\n",
        "    running_train_loss     = 0\n",
        "\n",
        "    running_test_accuracy = 0\n",
        "    running_test_loss     = 0\n",
        "\n",
        "    n_iters_train = len(x_train)/batch_size\n",
        "    n_iters_test  = len(x_test)/batch_size\n",
        "\n",
        "    # train the model (for each mini-batch)\n",
        "    model.train()\n",
        "    for index in range(0, len(x_train), batch_size):\n",
        "      x_batch = x_train[index:index+batch_size]\n",
        "      y_batch = y_train[index:index+batch_size]\n",
        "      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "      train_accuracy, train_loss = train(x_batch, y_batch, model, criterion, model_optimizer)\n",
        "      \n",
        "      # update metrics\n",
        "      running_train_accuracy += train_accuracy.item()\n",
        "      running_train_loss     += train_loss.item()\n",
        "\n",
        "    # test the model\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "\n",
        "      test_pred, test_truth = [], []\n",
        "\n",
        "      for index in range(0, len(x_test), batch_size):\n",
        "        x_batch = x_test[index:index+batch_size]\n",
        "        y_batch = y_test[index:index+batch_size]\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "      test_accuracy, test_loss, pred, truth = test(x_batch, y_batch, model, criterion)\n",
        "      \n",
        "      # update metrics\n",
        "      running_test_accuracy += test_accuracy.item()\n",
        "      running_test_loss     += test_loss.item()\n",
        "      \n",
        "      # append to the end of the prediction and ground truth lists\n",
        "      test_pred.extend(pred)\n",
        "      test_truth.extend(truth)\n",
        "  \n",
        "\n",
        "    # mean metrics\n",
        "    avg_train_accuracy = running_train_accuracy/n_iters_train\n",
        "    avg_train_loss     = running_train_loss/n_iters_train\n",
        "  \n",
        "    avg_test_accuracy  = running_test_accuracy/n_iters_test\n",
        "    avg_test_loss      = running_test_loss/n_iters_test\n",
        "  \n",
        "    # append checkpoints to model history\n",
        "    history.append({\"fold\" : fold + 1, \"epoch\" : epoch + 1, \"avg_train_accuracy\" : avg_train_accuracy * 100, \n",
        "                    \"avg_test_accuracy\" : avg_test_accuracy * 100, \"avg_train_loss\" : avg_train_loss, \"avg_test_loss\" : avg_test_loss,\n",
        "                    \"test_pred\" : test_pred, \"test_truth\" : test_truth})\n",
        "    \n",
        "    # print progress\n",
        "    print_progress(fold, epoch, n_epochs, avg_train_accuracy, avg_train_loss, avg_test_accuracy, avg_test_loss)\n",
        "\n",
        "    # save progress\n",
        "    save_progress(fold, epoch, avg_test_accuracy, model, model_optimizer)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGSH1fd3H8_C"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG-DDbUeIpOr"
      },
      "source": [
        "## Some imports and initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tln3Wox_H8e2"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "import seaborn as sb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "\n",
        "res = results(\"history.csv\")\n",
        "\n",
        "labels = [\"Anger\", \"Contempt\", \"Disgust\", \"Fear\", \"Happiness\", \"Sadness\", \"Surprise\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "braPC8GDBACJ"
      },
      "source": [
        "# Utility functions\n",
        "## Get test predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGgl0G7qBBWc"
      },
      "outputs": [],
      "source": [
        "def get_test_pred(fold, epoch):\n",
        "  df = pd.read_csv(res)\n",
        "  filter = (df[\"fold\"] == fold) & (df[\"epoch\"] == epoch)\n",
        "  test_pred = df.loc[filter, \"test_pred\"].item()\n",
        "  test_pred = ast.literal_eval(test_pred)\n",
        "\n",
        "  return test_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgL15DTtCIPc"
      },
      "source": [
        "## Get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7bjORDLCRpg"
      },
      "outputs": [],
      "source": [
        "def get_data(metric):\n",
        "  list = []\n",
        "  df = pd.read_csv(res)\n",
        "  for fold in range(5):\n",
        "    filter = df[\"fold\"] == fold + 1\n",
        "    train_accuracy = df.loc[filter, metric].tolist()\n",
        "    list.append(train_accuracy)\n",
        "  \n",
        "  return list "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw2fvpfkCyET"
      },
      "source": [
        "## Get truth values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7fB0qF3C4wM"
      },
      "outputs": [],
      "source": [
        "def get_test_truth(fold, epoch):\n",
        "  df = pd.read_csv(res)\n",
        "  filter = (df[\"fold\"] == fold) & (df[\"epoch\"] == epoch)\n",
        "  test_truth = df.loc[filter, \"test_truth\"].item()\n",
        "  test_truth = ast.literal_eval(test_truth)\n",
        "\n",
        "  return test_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNprywfGDdho"
      },
      "source": [
        "## Get metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NpxOENRDesM"
      },
      "outputs": [],
      "source": [
        "def get_metric(metric):\n",
        "  if metric == \"accuracy\":\n",
        "    train_output = get_data(\"avg_train_accuracy\")\n",
        "    test_output  = get_data(\"avg_test_accuracy\")\n",
        "  else:\n",
        "    train_output = get_data(\"avg_train_loss\")\n",
        "    test_output  = get_data(\"avg_test_loss\")\n",
        "  \n",
        "  filename = results(\"train_test_{:s}\".format(metric))\n",
        "\n",
        "  return train_output, test_output, filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB5oTWDRGK4t"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOIeC3nZGM-Y"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(fold, epoch=25):\n",
        "  test_pred  = get_test_pred(fold=fold, epoch=epoch)\n",
        "  test_truth = get_test_truth(fold=fold, epoch=epoch)\n",
        "\n",
        "  matrix = cm(test_truth, test_pred)\n",
        "  matrix = (matrix.T / matrix.astype(np.float).sum(axis=1)).T\n",
        "  matrix_df = pd.DataFrame(matrxi, labels, labels)\n",
        "\n",
        "  filename = results(\"confusion_matrix-fold{:d}\".format(fold))\n",
        "\n",
        "  return matrix_df, filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbcx5fMnHzS-"
      },
      "source": [
        "## Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HeqlUNBH2L7"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(fold):\n",
        "  matrix_df, filename = confusion_matrix(fold=fold)\n",
        "\n",
        "  ax = sb.heatmap(matrix_df, annot=True, cmap=\"Y1GnBu\")\n",
        "  ax.set(ylabel=\"True\", xlabel=\"Predicted\")\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.savefig(filename, bbox_inches=\"tight\", dpi=200)\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLHdqIcTIr7I"
      },
      "source": [
        "## Plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07DzPVs7IuG8"
      },
      "outputs": [],
      "source": [
        "def plot_metrics():\n",
        "  metrics = [\"accuracy\", \"loss\"]\n",
        "\n",
        "  for metric in metrics:\n",
        "    x_axis = [epoch for epoch in range(25)]\n",
        "    train_output, test_output, filename = get_metric(metric)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "    for fold in range(5):\n",
        "      ax1.plot(x_axis, train_output[fold], label=\"fold {:d}\".format(fold))\n",
        "      ax2.plot(x_axis, test_output[fold], label=\"fold {:d}\".format(fold))\n",
        "    \n",
        "    ax1.set_xlabel(\"epochs\")\n",
        "    ax1.set_ylabel(metric)\n",
        "    ax1.set_title(\"train {:s}\".format(metric))\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.set_xlabel(\"epochs\")\n",
        "    ax2.set_title(\"test {:s}\".format(metric))\n",
        "    ax2.legend()\n",
        "\n",
        "    ratio = 0.8\n",
        "\n",
        "    for ax in [ax1, ax2]:\n",
        "      xmin, xmax = ax.get_xlim()\n",
        "      ymin, ymax = ax.get_ylim()\n",
        "      ax.set_aspect(abs((xmax - xmin)/(ymax-ymin)) * ratio, adjustable=\"box\")\n",
        "    \n",
        "    plt.savefig(filename, bbox_inches=\"tight\", dpi=200)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8gcA9YhMg79"
      },
      "source": [
        "# Run the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yULlx9aSMjL0"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "  x, y = load_dataset()\n",
        "  folds = kfold(x, y, 5)\n",
        "\n",
        "  for repeat in range(3):\n",
        "\n",
        "    for fold, (x_train, y_train, x_test, y_test) in enumerate(folds):\n",
        "      x_train, y_train, x_test, y_test = convert_to_torch(x_train, y_train, x_test, y_test)\n",
        "\n",
        "      model = initialize()\n",
        "      run_model(fold, model, x_train, y_train, x_test, y_test)\n",
        "\n",
        "      dump_dict_list(res)\n",
        "\n",
        "\n",
        "  print(\"Start plotting\")\n",
        "  print(\"\")\n",
        "\n",
        "  plot_metrics()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjdlFcxrN38n"
      },
      "outputs": [],
      "source": [
        "run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeXpression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}